{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Relativistic Raytracer\n",
    "*PC6432 Project*\n",
    "\n",
    "*brought to you by @chas-card, @owl10124, and @TheRealOrange*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from array import array\n",
    "from PIL import Image\n",
    "from stl import mesh\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "np_type = np.float32\n",
    "c = 8 #3e8\n",
    "\n",
    "FARAWAY = 1.0e+39  # A large distance (i cant forsee how this will go wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def norm(arr): return arr / np.sqrt(np.sum(np.square(arr), axis=0))\n",
    "\n",
    "\n",
    "def lt_velo(lt, velo):\n",
    "    if len(np.shape(velo)) == 1:\n",
    "        velo = velo[:, np.newaxis]\n",
    "    v4 = np.concatenate((np.array([c * np.ones(np.shape(velo)[1])]), velo), axis=0)\n",
    "    vp4 = lt @ v4\n",
    "    return vp4[1:] * c / vp4[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Background\n",
    "Special Relativity is understood to produce effects including length contraction or time dilation, however problems about these effects tend to focus on 1 dimensional lengths.\n",
    "\n",
    "Instead, to more intuitively grasp these effects, let’s visualise these from 3D objects.\n",
    "\n",
    "Ultimately these are commonly asked questions with various past works exploring specific aspects of relativity.\n",
    "## References\n",
    "[Report by an MIT computer graphics team on Visualising Fast Objects](https://groups.csail.mit.edu/graphics/classes/6.837/F97/projects/reports/team19.pdf)\n",
    "MIT team did a short exploration into visualising very fast objects, \n",
    "modifying existing ray tracing libraries to account for Lorentz transforms of rays and doppler shift of resulting colors, \n",
    "making a few observations like how objects have apparent “stretch” and rotate (Terrell rotation)\n",
    "\n",
    "[spacetimetravel.org](https://spacetimetravel.org)\n",
    "An entire site dedicated to exploring visualisations of theory of relativity, simulating phenomena to demonstrate effects. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Visualising our objects - Rendering by ray tracing\n",
    "To “see” our objects, we need some way of peering into our 3D world and drawing an image.\n",
    "Thankfully this is also a common problem and many algorithms exist,\n",
    "we draw from [*James Bowman’s implementation*](https://excamera.com/sphinx/article-ray.html) of a ray tracing algorithm in python for how our raytracer logic will work\n",
    "[*https://excamera.com/sphinx/article-ray.html*](https://excamera.com/sphinx/article-ray.html)\n",
    "\n",
    "![image](references/coord_frames.png)\n",
    "*Existing library only has spheres and limited in scope, we mainly reference for logic\n",
    "*also a note for coordinate system*\n",
    "\n",
    "**Other references we used**\n",
    "[Medium article on ray tracing python from scratch](https://medium.com/swlh/ray-tracing-from-scratch-in-python-41670e6a96f9)\n",
    "also used as reference for explanation\n",
    "\n",
    "[ScratchAPixel](https://www.scratchapixel.com/)\n",
    "Resource on computer graphics basics\n",
    "\n",
    "**Ray tracing** mimics how light from sources bounce off objects an land onto a camera to produce an image.\n",
    "\n",
    "However, instead of actually simulating vast amounts of rays of light from a light source, only to filter the few rays which reach the camera.\n",
    "We apply the reverse, projecting rays from the camera and simulating where those rays reach.\n",
    "If a ray “hits” an object, then part of the “light” reflects perfectly while the rest diffuses, some rays might travel straight at the light source, hence those pixels will be very bright, while some may never intersect anything and have black background colour, and so on.\n",
    "![image](references/1_unARAf_8oLsXAQVp3obY0Q.jpeg)\n",
    "*from Medium article*\n",
    "\n",
    "This way of tracing a ray’s path from the camera to a source is a common rendering technique called the ray casting algorithm\n",
    "Of course, this simple definition would treat all objects as perfect mirrors, and only rays which reflect perfectly to a light source would be bright. For more realistic shading and simulating diffuse lighting we also implement the Blinn-Phong reflection model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Implementation\n",
    "## Frame\n",
    "\n",
    "We implement the obvious important concept in SR: the transform between inertial reference frames.\n",
    "\n",
    "Each frame has a velocity vector, giving rise to its own LT.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Lorentz Transformation\n",
    "\n",
    "Since we are dealing with a generalised LT which is capable of transforming reference frames which have relative velocities on more than one axis, the LT is in the form of a 4 by 4 matrix, shown below\n",
    "$$\n",
    "{\\displaystyle \\mathcal{L}(\\mathbf {v} )={\\begin{bmatrix}\\gamma &-\\gamma v_{x}/c&-\\gamma v_{y}/c&-\\gamma v_{z}/c\\\\-\\gamma v_{x}/c&1+(\\gamma -1){\\dfrac {v_{x}^{2}}{v^{2}}}&(\\gamma -1){\\dfrac {v_{x}v_{y}}{v^{2}}}&(\\gamma -1){\\dfrac {v_{x}v_{z}}{v^{2}}}\\\\-\\gamma v_{y}/c&(\\gamma -1){\\dfrac {v_{y}v_{x}}{v^{2}}}&1+(\\gamma -1){\\dfrac {v_{y}^{2}}{v^{2}}}&(\\gamma -1){\\dfrac {v_{y}v_{z}}{v^{2}}}\\\\-\\gamma v_{z}/c&(\\gamma -1){\\dfrac {v_{z}v_{x}}{v^{2}}}&(\\gamma -1){\\dfrac {v_{z}v_{y}}{v^{2}}}&1+(\\gamma -1){\\dfrac {v_{z}^{2}}{v^{2}}}\\end{bmatrix}}}\n",
    "$$\n",
    "\n",
    "Where $\\gamma$ is the Lorentz factor, and $v_x$, $v_y$, $v_z$ are the 3 cartesian coordinate components of the velocity vector, and $v = \\sqrt{{v_x}^2 + {v_y}^2 + {v_z}^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Defining Frames for Computation\n",
    "\n",
    "We also define each frame relative to another frame. At the 'bottom', or the 'root' of the tree of references is a world frame. All the frames which are defined are either in the 'special' world frame or relative to it, either directly or recursively through another frame. This way, we can transform from any frame to any other frame by first transforming 'up' to the world frame, then transforming 'down' the chain of references to any other frame.\n",
    "\n",
    "Furthermore, since LTs have the special property where multiplication with another LT also produces an LT, we can use this property to generate a single LT for transforming from one frame to another simply by multiplying all the LTs along the reference chain together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# frame class to handle defining different reference frames with respect to other reference frames\n",
    "# world frame is just (0, 0, 0, 0) position, use it as a \"special\" frame to transform between any frames\n",
    "class Frame:\n",
    "    def __init__(self, velocity, ref=None):\n",
    "        self.velocity = np.array(velocity, dtype=np_type)\n",
    "        self.ref = ref\n",
    "\n",
    "    @property\n",
    "    def lt(self):\n",
    "        b = self.velocity / c\n",
    "        b2 = np.sum(np.square(b))\n",
    "        assert (b2 <= 1)\n",
    "\n",
    "        g = 1 / (np.sqrt(1 - b2))\n",
    "\n",
    "        lt_mat = np.eye(4, dtype=np_type)\n",
    "        if b2 == 0:\n",
    "            return lt_mat\n",
    "\n",
    "        lt_mat[0, 0] = g\n",
    "        lt_mat[0, 1:] = lt_mat[1:, 0] = -b * g\n",
    "        lt_mat[1:, 1:] += (g - 1) * np.matmul(b[np.newaxis].T, b[np.newaxis]) / b2\n",
    "\n",
    "        assert (abs(np.linalg.det(lt_mat) - 1) < 1e-3)\n",
    "        return lt_mat\n",
    "\n",
    "    @property\n",
    "    def inv_lt(self):\n",
    "        inv_lt_mat = self.lt\n",
    "        inv_lt_mat[0, 1:] = -inv_lt_mat[0, 1:]\n",
    "        inv_lt_mat[1:, 0] = -inv_lt_mat[1:, 0]\n",
    "        return inv_lt_mat\n",
    "\n",
    "    @property\n",
    "    def to_world_lt(self):\n",
    "        if self.ref is None:\n",
    "            return self.inv_lt\n",
    "        else:\n",
    "            return np.matmul(self.ref.to_world_lt, self.inv_lt)\n",
    "\n",
    "    @property\n",
    "    def from_world_lt(self):\n",
    "        if self.ref is None:\n",
    "            return self.lt\n",
    "        else:\n",
    "            return np.matmul(self.lt, self.ref.from_world_lt)\n",
    "\n",
    "    def compute_lt_to_frame(self, frame):\n",
    "        if not frame:\n",
    "            return self.to_world_lt\n",
    "        return np.matmul(frame.from_world_lt, self.to_world_lt)\n",
    "\n",
    "    def compute_lt_from_frame(self, frame):\n",
    "        if not frame:\n",
    "            return self.from_world_lt\n",
    "        return np.matmul(self.from_world_lt, frame.to_world_lt)\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Frame with velocity \" + str(self.velocity) + \" wrt \" + str(self.ref)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Raytracing and LTs\n",
    "\n",
    "Raytracing involves taking a bunch of rays and running, for each object, two functions.\n",
    "Intersect: calculates your distance to the ray’s source. This tells us if you’re closest to the ray, and thus lets you filter which rays are your problem.\n",
    "\n",
    "Light: does the actual heavy lifting on determining your rays’ colour. This often involves some fancy operations and shaders:\n",
    "\n",
    "- Blinn-Phong reflection model: assuming some light will reach light source and treating intersect point as darker if intersect angle is more tangent\n",
    "- Reflections: reflect the rays about normals, and do another pass of raytracing from there (bounce).\n",
    "\n",
    "By raytracing all the camera’s rays, you get the image — “easy”.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "## Camera\n",
    "\n",
    "This does exactly what you’d expect: it provides an origin (point) and directions (normalised) for every pixel of the screen. \n",
    "\n",
    "(Previously this implemented abstractions for transforming the origin and directions, but these proved quite simple with the nature of LTs.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Camera:\n",
    "    def __init__(self, time, pos, rotn, dof, frame, bounces, res=(640,480)):  # rotn (x axis, y axis)\n",
    "        self.point = None\n",
    "        self.w, self.h = res\n",
    "        self.ray_dirs = None\n",
    "        self.screen_coords = None\n",
    "        self.time = time\n",
    "        self.pos = pos\n",
    "        self.rotn = rotn\n",
    "        self.dof = dof\n",
    "        self.frame = frame\n",
    "        self.bounces = bounces\n",
    "        self.calc_rays()\n",
    "\n",
    "    def calc_rays(self):\n",
    "        x, y, z = self.pos\n",
    "        self.point = np.array((self.time * c, x, y, z + self.dof), dtype=np_type)\n",
    "\n",
    "        r = float(self.w) / self.h\n",
    "        # Screen coordinates: x0, y0, x1, y1.\n",
    "        S = 10 * np.array((-1, 1 / r, 1, -1 / r))\n",
    "        x = np.tile(np.linspace(S[0], S[2], self.w), self.h)\n",
    "        y = np.repeat(np.linspace(S[1], S[3], self.h), self.w)\n",
    "\n",
    "        sigma, theta = self.rotn\n",
    "        rotmat = np.array([[1, 0, 0, 0], [0, np.cos(sigma), 0, np.sin(sigma)], [0, 0, 1, 0],\n",
    "                           [0, -np.sin(sigma), 0, np.cos(sigma)]], dtype=np_type) @ np.array(\n",
    "            [[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, np.cos(theta), np.sin(theta)], [0, 0, -np.sin(theta), np.cos(theta)]],\n",
    "            dtype=np_type)\n",
    "        self.screen_coords = rotmat @ np.stack((np.full((x.shape[0],), self.time * c), x, y, np.zeros(x.shape[0])),\n",
    "                                               axis=0) + self.point[:, np.newaxis]\n",
    "        self.point += rotmat @ np.array([0, 0, 0, -self.dof], dtype=np_type)\n",
    "\n",
    "        self.ray_dirs = norm((self.screen_coords - self.point[:, np.newaxis])[1:])\n",
    "\n",
    "    def set_time(self, t):\n",
    "        self.time = t\n",
    "        self.calc_rays()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## But! Special relativity?!\n",
    "\n",
    "We want to account for the speed of light being finite: the object has moved between the time of light ray capture and emission. Normals and directions may also be scuffed.\n",
    "\n",
    "To mitigate this: we consider the **reference frame** of the object (assuming constant velocity), in which the object is stationary! It’s still an inertial frame so we can just work in it.\n",
    "\n",
    "(We assume all frames share an origin: we didn’t want to do that at first, but then realised that there was no clear reversible way to set a ‘shared zero time’, and conversion would be painful.)\n",
    "\n",
    "### Helper functions\n",
    "\n",
    "We wrap `intersect` and `light` in helper functions — `intersect_frame` and `light_frame` — which Lorentz-transform the directions / light rays / coordinates / distances **in and out of** the object’s frame.\n",
    "- (4D) Positions: simply premultiply LT\n",
    "- Velocities: premultiply LT to (c,vx,vy,vz) to get (cdt’,dx’,dy’,dz’), then divide the last three elements by the first. `4d[1:]/4d[0]`\n",
    "- Directions (unit vectors): treat the normal vector as a speed of light, because it’s invariant under LTs. I find this quite hilarious.\n",
    "- Distances (scalars): Convert to positions, transform those, convert back.\n",
    "\n",
    "Specifically, it’s safe to directly take $b’=|\\mathcal L(b\\hat x)|$.\n",
    "\n",
    "### Accounting for time\n",
    "\n",
    "Time is no longer a constant for each intersection point: indeed, remember we are raytracing backwards through time! \n",
    "\n",
    "We account for this in the `light` function itself, which operates on the ray’s intersection point: we note the time position of this intersection, namely **(ray length)/c** subtracted from source time. Again, remember the frame doesn’t matter.\n",
    "\n",
    "This yields us a 4-dimensional position, which we use for further transforms.\n",
    "\n",
    "- The effects of time (regarding speed and thus displacement of other objects) are actually **accounted for** by the LT / frame shifts themselves. These affect the position of the ray in other frames.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Object\n",
    "\n",
    "One class to rule them all; it carries these four functions.\n",
    "In general `light_frame` and `intersect_frame` are constant, `light` is material-dependent (geometry-independent) and `intersect` is geometry-dependent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Object:\n",
    "\n",
    "    def __init__(self, position, frame, diffuse, mirror=0.2):\n",
    "        \"\"\"\n",
    "\n",
    "        :param array position: array of x y z position\n",
    "        :param frame: the reference frame to define the position and velocity of the object\n",
    "        :param array diffuse: RGB colour (from 0 to 1)\n",
    "        :param float mirror: how much to reflect\n",
    "        \"\"\"\n",
    "        self.position = np.array(position, dtype=np_type)\n",
    "        self.frame = frame\n",
    "        self.diffuse = np.array(diffuse, dtype=np_type)\n",
    "        self.mirror = mirror\n",
    "\n",
    "    def intersect_frame(self, source, dirs, frame):\n",
    "        \"\"\"\n",
    "\n",
    "        :param frame: frame from which the source rays are projected from\n",
    "        :param dirs: direction of the N rays cast from the N sources | shape(3, N)\n",
    "        :param source: position and time of the N sources | shape(4, N)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        lt = frame.compute_lt_to_frame(self.frame)\n",
    "        pt, dirs = lt @ source, -norm(lt_velo(lt, -dirs * c) / c)\n",
    "\n",
    "        time, pos = pt[0], pt[1:]\n",
    "        (dists, norms) = self.intersect(pos, dirs)\n",
    "\n",
    "        v4 = np.concatenate(([-dists], (dirs * dists)), axis=0)\n",
    "        return np.sqrt(np.sum(np.square(((frame.compute_lt_from_frame(self.frame) @ v4)[1:]).T), axis=1)), norms\n",
    "\n",
    "    def light_frame(self, source, dirs, dists, norms, frame, scene, bounce):\n",
    "        \"\"\"\n",
    "\n",
    "        :param int bounce: number of bounces remaining\n",
    "        :param scene: scene\n",
    "        :param frame: frame from which the source rays are projected from\n",
    "        :param norms: object-frame face normals | shape(N, 3)\n",
    "        :param dists: ray intersect distances | shape(N,)\n",
    "        :param dirs: direction of the N rays cast from the N sources | shape(3, N)\n",
    "        :param source: position and time of the N sources | shape(4, N)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        lt = frame.compute_lt_to_frame(self.frame)\n",
    "        v4 = np.concatenate(([-dists], (dirs * dists)), axis=0)\n",
    "\n",
    "        pt, dirs = lt @ source, -norm(lt_velo(lt, -dirs * c) / c)\n",
    "        dists = np.sqrt(np.sum(np.square((lt @ v4)[1:]).T, axis=1))\n",
    "\n",
    "        return self.light(pt, dirs, dists, norms, scene, bounce)\n",
    "\n",
    "    def diffuseColor(self, M):\n",
    "        \"\"\"\n",
    "\n",
    "        :param np.ndarray M: intersection point(s) | shape(N, 3)\n",
    "        :return: colour(s)\n",
    "        \"\"\"\n",
    "        return self.diffuse\n",
    "\n",
    "    def intersect(self, source, direction):\n",
    "        \"\"\"\n",
    "        Ray to Object Intersect function\n",
    "\n",
    "        :param np.ndarray source: ray source position vector | shape(3, N)\n",
    "        :param np.ndarray direction: rays direction unit vector | shape(3, N)\n",
    "        :return: intersection distance for each ray  shape(N,)\n",
    "        \"\"\"\n",
    "        return np.full(direction.shape[1], FARAWAY)  # default return array of FARAWAY (no intersect)\n",
    "\n",
    "    def light(self, source, dirs, dists, norms, scene, bounce):\n",
    "        \"\"\"\n",
    "        Recursive raytrace function\n",
    "\n",
    "        :param np.ndarray source: position and time of the N sources | shape(4, N)\n",
    "        :param np.ndarray dirs: direction of the N rays cast from the N sources | shape(3, N)\n",
    "        :param np.ndarray dists: ray intersect distances | shape(N,)\n",
    "        :param np.ndarray norms: object-frame face normals | shape(N, 3)\n",
    "        :param scene: array of Object instances\n",
    "        :param int bounce: number of bounces remaining\n",
    "        :return: array of colours for each pixel | shape(N,3)\n",
    "        \"\"\"\n",
    "        time = source[0] - dists\n",
    "        pts = source[1:] + dirs * dists.T\n",
    "        tol = self.dirs_to_thing(scene.light, np.concatenate([[time], pts], axis=0), None)\n",
    "        toc = self.dirs_to_thing(scene.camera.point[1:], np.concatenate([[time], pts], axis=0), scene.camera.frame)\n",
    "        nudged = pts + norms * .0001  # default return all black\n",
    "\n",
    "        # return np.array([self.diffuseColor(pts)]*len(dists))\n",
    "\n",
    "        n4d = np.concatenate(([time], nudged), axis=0)  # TODO\n",
    "        distsl = [s.intersect_frame(n4d, tol, self.frame)[0] for s in scene.objs]\n",
    "\n",
    "        nearl = np.amin(distsl, axis=0)\n",
    "        seelight = nearl > 1e30\n",
    "        color = np.array([[.05] * 3] * len(dists))\n",
    "\n",
    "        lv = np.maximum(np.einsum(\"ij,ij->j\", norms, tol), 0.1)\n",
    "        color += np.outer((lv * seelight), self.diffuseColor(pts))\n",
    "        color += np.outer(lv, self.diffuseColor(pts))\n",
    "\n",
    "        if bounce < scene.camera.bounces:\n",
    "            nray = norm(dirs - 2 * norms * np.einsum(\"ij,ij->j\", dirs, norms))\n",
    "            color += scene.raytrace(n4d, nray, self.frame, bounce + 1) * self.mirror\n",
    "\n",
    "        phong = np.einsum(\"ij,ij->j\", norms, norm(tol + toc))\n",
    "        # color += np.outer((np.power(np.clip(phong, 0, 1), 50)), np.ones(3))\n",
    "        color += np.outer((np.power(np.clip(phong, 0, 1), 50) * seelight), np.ones(3))\n",
    "\n",
    "        return color\n",
    "        # return np.full(direction.shape[1], self.diffuseColor(None))    # default return all black\n",
    "\n",
    "    def dirs_to_thing(self, thing, pos, thingframe):\n",
    "        dirs = thing[:, np.newaxis] - (self.frame.compute_lt_to_frame(thingframe) @ pos)[1:]\n",
    "        return -norm(lt_velo(self.frame.compute_lt_from_frame(thingframe), -dirs))\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.__class__.__name__ + \" at position \" + str(self.position) + \" with color \" + str(\n",
    "            self.diffuse) + \" in frame: \" + str(self.frame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### SphereObject\n",
    "`intersect`: solves a quadratic equation to determine sphere intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SphereObject(Object):\n",
    "    def __init__(self, position, frame, diffuse, radius):\n",
    "        super().__init__(position, frame, diffuse)\n",
    "        self.radius = radius\n",
    "\n",
    "    def intersect(self, source, direction):  # this is refactored and likely broken btw just check\n",
    "        b = 2 * np.einsum(\"ij,ij->j\", direction, source - self.position[:, np.newaxis])\n",
    "        see = np.sum(np.square(self.position)) + np.sum(np.square(source), axis=0) - 2 * np.dot(self.position,\n",
    "                                                                                                source) - (\n",
    "                      self.radius ** 2)\n",
    "\n",
    "        disc = np.square(b) - (4 * see)\n",
    "        sq = np.sqrt(np.maximum(0, disc))\n",
    "        h0 = (-b - sq) / 2\n",
    "        h1 = (-b + sq) / 2\n",
    "        h = np.where((h0 > 0) & (h0 < h1), h0, h1)\n",
    "        pred = (disc > 0) & (h > 0)\n",
    "        return (\n",
    "            np.where(pred, h, FARAWAY),\n",
    "            np.where(pred[np.newaxis, :],\n",
    "                     (source - self.position[:, np.newaxis] + np.einsum(\"ij,j->ij\", direction, h)) / self.radius,\n",
    "                     np.zeros(np.shape(direction)))\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### MeshObject\n",
    "A direct import from an .stl file, with a numpy-optimised intersection function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MeshObject(Object):\n",
    "    def __init__(self, position, frame, mesh, diffuse, mirror=0.1):\n",
    "        super().__init__(position, frame, diffuse, mirror=mirror)\n",
    "        self.m = mesh\n",
    "        self.m.translate(position)\n",
    "        self.chunksize = 200\n",
    "\n",
    "    def intersect(self, source, direction):\n",
    "        m = self.m\n",
    "        meshN = m.get_unit_normals()\n",
    "\n",
    "        # array of intersect lengths for ALL triangles\n",
    "        t_overall = np.full(direction.shape[1], FARAWAY)  # initialize to assume all distances are FARAWAY\n",
    "        N_overall = np.full(direction.shape, 0, dtype=np_type).T\n",
    "\n",
    "        polygons = meshN.shape[0]\n",
    "        N = math.ceil(polygons / self.chunksize)\n",
    "\n",
    "        chunks = [min((i + 1) * self.chunksize, polygons) for i in range(N)]\n",
    "        meshN_chunks = np.array_split(meshN, chunks, axis=0)\n",
    "        v0_chunks = np.array_split(m.v0, chunks, axis=0)\n",
    "        v1_chunks = np.array_split(m.v1, chunks, axis=0)\n",
    "        v2_chunks = np.array_split(m.v2, chunks, axis=0)\n",
    "\n",
    "        eijk = np.zeros((3, 3, 3))\n",
    "        eijk[0, 1, 2] = eijk[1, 2, 0] = eijk[2, 0, 1] = 1\n",
    "        eijk[0, 2, 1] = eijk[2, 1, 0] = eijk[1, 0, 2] = -1\n",
    "\n",
    "        done_size = 0\n",
    "        path1 = None\n",
    "        path2 = None\n",
    "        for i in range(N):\n",
    "            curr_size = meshN_chunks[i].shape[0]\n",
    "            intersectLens = np.einsum(\"at,tb->ab\", meshN_chunks[i], direction)\n",
    "\n",
    "            intersectLens = np.where(intersectLens == 0, 1 / FARAWAY, intersectLens)\n",
    "\n",
    "            t = np.einsum(\"ab,ab->ab\",\n",
    "                          np.einsum(\"abt,at->ab\", (v0_chunks[i][:, np.newaxis, :] - source.T[np.newaxis, :, :]),\n",
    "                                    meshN_chunks[i]), np.reciprocal(intersectLens))\n",
    "            t = np.where(t < 0, FARAWAY, t)\n",
    "\n",
    "            P = source.T[np.newaxis] + np.einsum(\"ab,cb->cba\", direction, t)\n",
    "\n",
    "            edge = (v1_chunks[i] - v0_chunks[i])\n",
    "            vp = P - v0_chunks[i][:, np.newaxis, :]\n",
    "            if path1 is None:\n",
    "                path_info = np.einsum_path(\"ijk,uj,uvk->uvi\", eijk, edge, vp, optimize='optimal')\n",
    "                path1 = path_info[0]\n",
    "                #print(path_info[1])\n",
    "            C = np.einsum(\"ijk,uj,uvk->uvi\", eijk, edge, vp, optimize=path1)\n",
    "            if path2 is None:\n",
    "                path_info = np.einsum_path(\"ab,acb->ac\", meshN_chunks[i], C, optimize='greedy')\n",
    "                path2 = path_info[0]\n",
    "                #print(path_info[1])\n",
    "            d = np.einsum(\"ab,acb->ac\", meshN_chunks[i], C, optimize=path2)\n",
    "            t = np.where(d < 0, FARAWAY, t)\n",
    "\n",
    "            edge = (v2_chunks[i] - v1_chunks[i])\n",
    "            vp = P - v1_chunks[i][:, np.newaxis, :]\n",
    "            C = np.einsum(\"ijk,uj,uvk->uvi\", eijk, edge, vp, optimize=path1)\n",
    "            d = np.einsum(\"ab,acb->ac\", meshN_chunks[i], C, optimize=path2)\n",
    "            t = np.where(d < 0, FARAWAY, t)\n",
    "\n",
    "            edge = (v0_chunks[i] - v2_chunks[i])\n",
    "            vp = P - v2_chunks[i][:, np.newaxis, :]\n",
    "            C = np.einsum(\"ijk,uj,uvk->uvi\", eijk, edge, vp, optimize=path1)\n",
    "            d = np.einsum(\"ab,acb->ac\", meshN_chunks[i], C, optimize=path2)\n",
    "            t = np.where(d < 0, FARAWAY, t)\n",
    "\n",
    "            min_t = np.min(t, axis=0)\n",
    "            done_size += curr_size\n",
    "            min_polygon = (t != FARAWAY) & (t == min_t[np.newaxis, :])\n",
    "            b = min_polygon[:, :, np.newaxis]\n",
    "            sel_n = np.sum(b * meshN_chunks[i][:, np.newaxis, :], axis=0)\n",
    "            N_overall += sel_n\n",
    "            t_overall = np.where(min_t < t_overall, min_t, t_overall)\n",
    "\n",
    "        return t_overall, N_overall.T\n",
    "\n",
    "    def chas_intersect(self, source, direction):\n",
    "        # numpy-stl mesh get normal vectors as unit vectors\n",
    "        m = self.m\n",
    "        meshN = self.m.get_unit_normals()\n",
    "\n",
    "        # array of intersect lengths for ALL triangles\n",
    "        # initialize to assume all distances are FARAWAY\n",
    "        t_overall = np.full(direction.shape[1], FARAWAY)\n",
    "\n",
    "        # array of intersect normals for ALL triangles\n",
    "        N_overall = np.full(direction.shape, 0).T\n",
    "\n",
    "        direction = direction.T\n",
    "        for i in range(0, len(m.v0)):\n",
    "            v1 = m.v0[i]  # point 1\n",
    "            v2 = m.v1[i]  # point 2\n",
    "            v3 = m.v2[i]  # point 3\n",
    "            N = meshN[i]\n",
    "\n",
    "            # INTERSECT TRIANGLE PLANE =================================\n",
    "            # compute intersect lengths to plane\n",
    "            intersectLens = direction.dot(N)\n",
    "            # Check if ray and plane are parallel\n",
    "            if intersectLens.all() == 0:\n",
    "                continue\t\t\t# no intersects\n",
    "            # intersect lengths to plane\n",
    "            t = (v1 - source.T).dot(N) / intersectLens\n",
    "            # check if triangle behind ray\n",
    "            t = np.where(t < 0, FARAWAY, t)\n",
    "            # intersection point(s) (individual vectors) using equation\n",
    "            P = source.T + direction * t[:,np.newaxis]\n",
    "            # END INTERSECT TRIANGLE PLANE =============================\n",
    "\n",
    "            # CHECK INSIDE/OUTSIDE =====================================\n",
    "            # whether intersect point within triangle area\n",
    "\n",
    "            edge = v2 - v1  # vector 1-2\n",
    "            vp = P - v1  # vector 1-P    array of such vectors\n",
    "            C = np.cross(edge, vp)  # C IS N x 3\n",
    "            t = np.where(np.dot(C, N) < 0, FARAWAY, t)\n",
    "\n",
    "            edge = v3 - v2  # vector 2-3\n",
    "            vp = P - v2  # vector 2-P    array of such vectors\n",
    "            C = np.cross(edge, vp)  # C IS N x 3\n",
    "            t = np.where(np.dot(C, N) < 0, FARAWAY, t)\n",
    "\n",
    "            edge = v1 - v3  # vector 3-1\n",
    "            vp = P - v3  # vector 3-P    array of such vectors\n",
    "            C = np.cross(edge, vp)  # C IS N x 3\n",
    "            t = np.where(np.dot(C, N) < 0, FARAWAY, t)\n",
    "\n",
    "            # END CHECK INSIDE/OUTSIDE =================================\n",
    "\n",
    "            # Get closest distances\n",
    "            t_overall = np.where(t < t_overall, t, t_overall)\n",
    "            # array of whether t < t_overall\n",
    "            tLess_bool = t < t_overall\n",
    "\n",
    "            # Get closest distances\n",
    "            t_overall = np.where(tLess_bool, t, t_overall)\n",
    "\n",
    "            # Add normals to N_overall (only if t was closer)\n",
    "            tLess_bool_broadcast = np.repeat(tLess_bool.reshape((1, len(tLess_bool))), 3, axis=0).T\n",
    "            N_overall = np.where(tLess_bool_broadcast, N, N_overall)\n",
    "\n",
    "        return (t_overall, N_overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Scene\n",
    "Ties this whole mess together by controlling general flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Scene:\n",
    "    def __init__(self, camera, light, objs):\n",
    "        self.camera = camera\n",
    "        self.light = light\n",
    "        self.objs = objs\n",
    "\n",
    "    def raytrace(self, source, dirs, frame, bounce=0):\n",
    "        res = [s.intersect_frame(source, dirs, frame) for s in self.objs]\n",
    "        color = np.zeros((np.shape(source)[1], 3))\n",
    "        if not res:\n",
    "            return color\n",
    "        dists, norms = zip(*res)  # (objects) x (screen dims)\n",
    "        nearest = np.amin(dists, axis=0)\n",
    "        for (s, d, n) in zip(self.objs, dists, norms):\n",
    "            # print(\"Bounce \"+str(bounce)+\" of \"+str(self.camera.bounces)+\": Raytracing object \"+str(s))\n",
    "            hit = (nearest < 1e30) & (d == nearest)\n",
    "            if np.any(hit):\n",
    "                sourcec = np.compress(hit, source, axis=1)\n",
    "                distsc = np.compress(hit, d)\n",
    "                dirsc = np.compress(hit, dirs, axis=1)\n",
    "                normsc = np.compress(hit, n, axis=1)\n",
    "                colorc = s.light_frame(sourcec, dirsc, distsc, normsc, frame, self, bounce)\n",
    "                ret = np.zeros((*hit.shape, 3))\n",
    "                for i in range(3):\n",
    "                    np.place(ret[:, i], hit, colorc[:, i])\n",
    "                color += ret\n",
    "        return color\n",
    "\n",
    "    def trace_scene(self):\n",
    "        return self.raytrace(np.array([self.camera.point] * np.shape(self.camera.ray_dirs)[1]).T, self.camera.ray_dirs,\n",
    "                             self.camera.frame, bounce=0)\n",
    "\n",
    "    def render(self):\n",
    "        return Image.merge(\"RGB\", [\n",
    "            Image.fromarray((255 * np.clip(see, 0, 1).reshape((self.camera.h, self.camera.w))).astype(np.uint8), \"L\")\n",
    "            for see in self.trace_scene().T]\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# A Test Render\n",
    "Each render may take a while... (roughly a minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene created\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGB size=640x480>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y = 5,3\n",
    "f0=Frame([0,0,0])\n",
    "\n",
    "cam = Camera(0,(0,800,-800),(0,-np.pi/6),20,f0,2)\n",
    "\n",
    "frames = [Frame(np.array((8.0,0,0))*(1-1/(1<<i))) for i in range(y)]\n",
    "boxes = [MeshObject(np.array(((i+4*j)*300,0,j*300)),frames[j],mesh.Mesh.from_file('models/block100.stl'),np.array((1-1/(1<<j),1,0))) for i in range(-x,x+1) for j in range(y)]\n",
    "#floor = SphereObject(np.array((0,-90100,0)),f0,np.array((0,0,.5)),90000)\n",
    "\n",
    "print(\"scene created\")\n",
    "\n",
    "scene = Scene(cam, np.array((2000, 10000, -3000)), boxes)#,floor])\n",
    "display(scene.render())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Results\n",
    "Some proofs of concept and cool renders we liked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Terrell Rotation\n",
    "We are all familiar with the concept of length contraction due to an object moving at relativistic speeds. But what does it actually look like? Turns out, it is not that straightforward, when you have to account for the time it takes for light rays from different parts of the object to reach the observer.\n",
    "\n",
    "Thanks to the differential in the time it takes for the light from parts of the object to reach the observer, a receding object would appear contracted, an approaching object would appear elongated (even considering length contraction) and a passing object would appear to be rotated, even though this is a purely optical effect; there is no real physical rotation occuring.\n",
    "\n",
    "Below is a sequence of images representing a row of cubes moving at progressively faster speeds.\n",
    "It is interesting to note that the first image represents the orientation as well as direction of all the cubes, yet the fast moving cubes appear to be rotated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3> v = 0.0c </h3> \n",
    "<img src=\"./outputs/final/img00.gif\" width=60% style=\"float:left;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3> v = 0.1c </h3>\n",
    "<img src=\"./outputs/final/imgg01.gif\" width=60% style=\"float:left;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3> v = 0.3c </h3>\n",
    "<img src=\"./outputs/final/imgg03.gif\" width=60% style=\"float:left;\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3> v = 0.5c </h3>\n",
    "<img src=\"./outputs/final/imgg05.gif\" width=60% style=\"float:left;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3> v = 0.7c </h3>\n",
    "<img src=\"./outputs/final/imgg07.gif\" width=60% style=\"float:left;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> v = 0.9c </h3>\n",
    "<img src=\"./outputs/final/imgg09.gif\" width=60% style=\"float:left;\"/>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "From the above animated GIFs one can observe what a cube moving at relativistic velocities would actually look like. The apparent rotation of the cube is due to the fact that the cube is moving a such a significant portionof the speed of light that light from a normally obscured face of the cube can now reach the observer because the cube is constantly moving out of the way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Ladder and the Barn Paradox\n",
    "\n",
    "The famous ladder and the barn paradox in special relativity is also simplified, when we explain that the observer in the same frame as the barn would simply see the ladder length contracted and vice versa, when in reality, what we would actually observe should we have a ladder and a barn with relativistic relative velocities is rather unclear.\n",
    "\n",
    "So, we construct the ladder and the barn paradox using our raytracer, by specifying a long cuboid representing the ladder, and a hollow \"barn\" with an opening on the side such that we can see the progress of the cuboid \"ladder\" through the \"barn\".\n",
    "\n",
    "The image below shows the setup with all objects stationary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"./assets/setup_barnladder_annotate.png\" width=40% style=\"float:left;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As can be seen above, the \"ladder\" is slightly longer than the \"barn\", such that one would conclude that the ladder must be unable to fit completely within the \"barn\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Raytraced Animation\n",
    "\n",
    "First let us see how the setup looks like with just the ladder and the barn.\n",
    "\n",
    "We will generate two renders, one where the camera is in the same frame of reference as the barn, and the other where the camera is in the same frame of reference as the ladder.\n",
    "\n",
    "The icosahedron is added just as a foreground feature to illustrate how the enviroment around the barn would behave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3> barn frame </h3>\n",
    "<img src=\"./outputs/train/img_tunnel_f.gif\" width=60% style=\"float:left;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3> ladder frame </h3>\n",
    "<img src=\"./outputs/train/img_train_f.gif\" width=60% style=\"float:left;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It is interesting to note that the block is nonetheless observed to fully fit within the barn despite the optical Terrell rotation effects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Now for the paradox!\n",
    "\n",
    "The typical setup for the paradox is such that for an observer in the frame of the barn, the doors on both sides of the barn are closed at for the time where the ladder is fully within the barn.\n",
    "\n",
    "To achieve this setup with the raytracer, it takes some amount of consideration, since this renderer does not feature the ability to have keyed/timed events.\n",
    "\n",
    "We represent the doors as two flat blocks which are moving at a constant velocity from a distance away, such that in the reference frame of the barn, the two flat blocks simultaneously cover the entrance and exit of the barn when the ladder is within the barn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3> barn frame </h3>\n",
    "<img src=\"./outputs/train/imgdoor_tunnel_f.gif\" width=60% style=\"float:left;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3> ladder frame </h3>\n",
    "<img src=\"./outputs/train/imgdoor_train_f.gif\" width=60% style=\"float:left;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This clearly illustrates how events which appear simultaneous in one frame may not appear so in other frames of reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}